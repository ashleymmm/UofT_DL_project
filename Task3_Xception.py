# -*- coding: utf-8 -*-
"""Task 3 - Xception Best Model

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mgp49SCmf4FAJ-V2umHMtl0fwat4_EVp

# Prep: Mounting Drive and Importing Libraries
"""

from google.colab import drive
from google.colab import files
drive.mount('/content/drive/')

# Commented out IPython magic to ensure Python compatibility.
# %cd 'drive/My Drive/AppliedDeepLearning/Data/CBIS-DDSM/'
#%ls

from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
from keras.applications.vgg16 import preprocess_input
from keras.applications.vgg16 import decode_predictions
from keras.applications.vgg16 import VGG16
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import pandas as pd
from keras.applications.vgg16 import preprocess_input
import keras,os
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPool2D , Flatten, Dropout
from keras.preprocessing.image import ImageDataGenerator
import numpy as np

from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import accuracy_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import binarize

import matplotlib.pyplot as plt

"""# CBIS-DDSM: Xception

# Training: Task 3

Load .csv files for training and test sets
"""

train = pd.read_csv('merged_train.csv')
# Create new identifier
ident = train['patient_id']+ '_' + train['left_or_right'] + '_' + train['image_view']
id = []
for i in range(0, len(ident)):
  id.append(ident[i] + '_' + str(train['abnormality_id'][i]))
train['id_long'] = id
train['id_short'] = ident

# validation set
test = pd.read_csv('merged_test.csv')
# Create new identifier
ident = test['patient_id']+ '_' + test['left_or_right'] + '_' + test['image_view']
id = []
for i in range(0, len(ident)):
  id.append(ident[i] + '_' + str(test['abnormality_id'][i]))
test['id_long'] = id
test['id_short'] = ident

"""Drop benign without call back"""

X_train = np.load('Task2_July5_Train_ROI.npy')
y_train = train['pathology'][0:len(X_train)]

from sklearn.model_selection import train_test_split
# Split dataset into trianing and validation sets
X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=123)

X_test = np.load('Task2_July5_Test_ROI.npy')
y_test = test['abnormality_type'][0:len(X_test)]

# This function binarizes the category (Malignant and Benign; note benign without callback is consideres as benign)
def binarize_abnormality(list):
  bin_list = []
  for k in list:
    if k == 'MALIGNANT':
      bin_list.append(1)
    else:
      bin_list.append(0)
  return bin_list

# After binarizing the labels, have to change it to one-hot-encoding using 'to_categorical' function
from keras.utils import to_categorical
y_train = binarize_abnormality(y_train)
y_valid = binarize_abnormality(y_valid)
y_train = to_categorical(y_train)
y_valid = to_categorical(y_valid)
y_test = binarize_abnormality(y_test)
y_test = to_categorical(y_test)

#Image Data Augmentation
train_generator = ImageDataGenerator(vertical_flip=True, horizontal_flip=True,rotation_range=90)

train_generator.fit(X_train)

# Specify the Xception tf weights
xception_tf = keras.applications.Xception(
    include_top=False,
    weights="imagenet",
    input_tensor=None,
    input_shape=(224,224,3))

# Adding the final layers to classify into 2 classes
np.random.seed(123)
model = Sequential()
model.add(xception_tf)
model.add(Flatten())
# #Adding the Dense layers along with activation and batch normalization
model.add(Dense(1024,activation=('relu'), input_dim=512, kernel_regularizer='l2'))
model.add(Dense(512,activation=('relu'), kernel_regularizer='l2'))
model.add(Dense(256,activation=('relu'), kernel_regularizer='l2'))
model.add(Dropout(0.2))
model.add(Dense(128,activation=('relu'), kernel_regularizer='l2'))
model.add(Dropout(0.2))
model.add(Dense(64,activation=('relu'), kernel_regularizer='l2'))
model.add(Dropout(0.2))
#model.add(layers.GlobalAveragePooling2D())
#model.add(Dropout(0.4))
model.add(keras.layers.BatchNormalization())
model.add(Dense(2,activation=('sigmoid')))

# Compile the model and set the parameters
from keras.optimizers import SGD, RMSprop
from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping

opt = keras.optimizers.RMSprop(learning_rate=0.00001,momentum=.9)
ls = keras.losses.binary_crossentropy
# Learning Rate
#lrr= ReduceLROnPlateau(monitor='val_loss', factor=.01, min_lr=1e-7) # Change the min_lr if needed, otherwise can leave it
#es = EarlyStopping(patience=15, verbose=1) # Don't have to add this, usually we want the loss to stabilize

model_name = 'InceptionV3-Task3'
mod_save = ModelCheckpoint(model_name, save_best_only=True, monitor='val_loss', mode='min') # IMPORTANT step: saves the model for future recalling
model.compile(loss=ls, optimizer=opt, metrics=['accuracy'])

history = model.fit_generator(train_generator.flow(X_train, y_train, batch_size=32, shuffle=True),
                              epochs = 70, validation_data = [X_valid, y_valid], callbacks=[mod_save], verbose=1)

"""Model Evaluation"""

plt.figure(figsize=(10,8)).suptitle('Loss Plot', fontsize = 20)
plt.plot(history.history['loss'], label = 'train')
plt.plot(history.history['val_loss'], label = 'validation')
plt.legend(fontsize = 18)
plt.ylabel('loss', fontsize = 18)
plt.xlabel('Epoch', fontsize = 18)
plt.savefig('loss_Task3_0726_Xception_22_0.00001RMS_OH.pdf')
#files.download('loss.pdf')

#model.load_weights('Task2_0709_DenseNet2_ash.h5')

x_test_value = np.load('Task2_July5_Test_ROI.npy')
y_hat = model.predict(x_test_value)
y_true = np.asarray(y_test)

# Convert prob to class, keep only class 1 (mass)
yhat = binarize(y_hat, 0.5)[:,1]
ytrue = y_true[:,1]

#acc
acc = accuracy_score(ytrue, yhat)
print(acc)

#AUC
auc = roc_auc_score(ytrue, yhat)
print(auc)

# Confusion matrix
cfm = confusion_matrix(ytrue, yhat)

TP = cfm[1,1]
TN = cfm[0,0]
FP = cfm[0,1]
FN = cfm[1,0]

print(cfm)

true_negative, false_positive, false_negative, true_positive  = cfm.ravel()
precision = true_positive / (true_positive + false_positive)
recall = true_positive / (true_positive + false_negative)
specificity = true_negative / (true_negative + false_positive)
print('Precison:{:.2f}'.format(precision))
print('Sensitivity:{:.2f}'.format(recall))
print('Specificity:{:.2f}'.format(specificity))