"""Task 2 - MobileNet

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s6EIcS5vnFNd3wGxkD_PNwFPuFiZs6qt

# Prep: Mounting Drive and Importing Libraries
"""

from google.colab import drive
drive.mount('/content/drive/')

# Commented out IPython magic to ensure Python compatibility.
# %cd '/content/drive/My Drive/AppliedDeepLearning/Data/CBIS-DDSM/'
#%cd 'drive/My Drive/AppliedDeepLearning/Data/CBIS-DDSM/'
# Full path: /content/drive/My Drive/AppliedDeepLearning/Data/CBIS-DDSM
# %ls # Listing the files in our current directory

from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
from keras.applications.vgg16 import preprocess_input
from keras.applications.vgg16 import decode_predictions
from keras.applications.vgg16 import VGG16
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import pandas as pd
from keras.applications.vgg16 import preprocess_input
import keras,os
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPool2D , Flatten, Dropout
from keras.preprocessing.image import ImageDataGenerator
import numpy as np

"""## Code for checking the data"""

# The code below checks if the image is normal, run it after loading the training set.
#from google.colab.patches import cv2_imshow
#cv2_imshow(X_train[3])

"""# Training: Task 2

Load .csv files for training and test sets
"""

#Please see (code) file to see how merged_traind and merged_test is created
train = pd.read_csv('merged_train.csv')

# Create new identifier
ident = train['patient_id']+ '_' + train['left_or_right'] + '_' + train['image_view']
id = []
for i in range(0, len(ident)):
  id.append(ident[i] + '_' + str(train['abnormality_id'][i]))
train['id_long'] = id
train['id_short'] = ident

# validation set
test = pd.read_csv('merged_test.csv')
# Create new identifier
ident = test['patient_id']+ '_' + test['left_or_right'] + '_' + test['image_view']
id = []
for i in range(0, len(ident)):
  id.append(ident[i] + '_' + str(test['abnormality_id'][i]))
test['id_long'] = id
test['id_short'] = ident

#Training Set - Please see (file) for how the training set is created
X_train = np.load('Task2_July5_Train_ROI.npy')
y_train = train['abnormality_type'][0:len(X_train)]

from sklearn.model_selection import train_test_split
# Split dataset into training and validation sets, random 8:2 split

X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=123)

#Test Set - Please see (file) for how the test set is created
X_test = np.load('Task2_July5_Test_ROI.npy')
y_test = test['abnormality_type'][0:len(X_test)]

# This function binarizes the category (otherwise the model will popout errors)
def binarize_abnormality(list):
  bin_list = []
  for k in list:
    if k == 'mass':
      bin_list.append(1)
    if k == 'calcification':
      bin_list.append(0)
  return bin_list

# After binarizing the labels, have to change it to one-hot-encoding using 'to_categorical' function
from keras.utils import to_categorical
y_train = binarize_abnormality(y_train)
y_valid = binarize_abnormality(y_valid)
y_train = to_categorical(y_train)
y_valid = to_categorical(y_valid)
y_test = binarize_abnormality(y_test)
y_test = to_categorical(y_test)

#Image Data Augmentation
train_generator = ImageDataGenerator(vertical_flip=True, horizontal_flip=True,rotation_range=90)

#Fitting the augmentation defined above to the data
train_generator.fit(X_train)

#Model: Using MobileNet as example, you can change this whenever
base_model = keras.applications.MobileNet(include_top = False, weights= "imagenet", input_shape = (224,224,3), classes = 2)

#Adding the final layers to the above base models where the actual classification is done in the dense layers
model = Sequential()
model.add(base_model)
model.add(Flatten())
#Adding the Dense layers along with activation and batch normalization
model.add(Dense(1024,activation=('relu'), input_dim=512))
model.add(Dense(512,activation=('relu')))
model.add(Dense(256,activation=('relu')))
model.add(Dropout(0.4))
model.add(Dense(128,activation=('relu')))
model.add(Dropout(0.4))
model.add(Dense(2,activation=('softmax')))

#Checking the final VGG16 model summary
model.summary()

"""Hyperparameters and model specs"""

#Defining the hyperparameters
from keras.optimizers import SGD, Adam, RMSprop
from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping
batch_size=32
learn_rate=0.001 # Initial learning rate
sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False) #Stochastic gradient descent

# Set model name
model_name = "MobileNet"

# Learning Rate
#lrr= ReduceLROnPlateau(monitor='val_loss', factor=.01, min_lr=1e-7) # Change the min_lr if needed, otherwise can leave it

mod_save = ModelCheckpoint(model_name, save_best_only=True, monitor='val_loss', mode='min') # IMPORTANT step: saves the model for future recalling
                           # The best moedel is the model with the lowest validation loss

es = EarlyStopping(patience=15, verbose=1) # Don't have to add this, usually we want the loss to stabilize

#Compile the model, MUST run this before calling model
model.compile(optimizer = sgd, loss = 'binary_crossentropy', metrics = ['accuracy'])

"""Next, we train the model.
The codes below basically does:
1.  Model training
2.  Plotting training and validation loss
3.  Load the best model
4.  Making predictions on the test set
5.  Evaluation on the test set to get the test loss and accuracy
6.  Create confusion matrix
7.  Calculate sensitivity, specificity
8.  Calculate AUC
"""

# Training the model
history = model.fit_generator(train_generator.flow(X_train, y_train, batch_size = batch_size, shuffle=True), epochs = 100,
                                    validation_data = [X_valid, y_valid],
                                    steps_per_epoch=X_train.shape[0]//batch_size,
                                    validation_steps=X_valid.shape[0]//batch_size, callbacks=[mod_save, es], verbose=1)

# Loss plot
plt.figure(figsize=(10,8)).suptitle('Loss Plot', fontsize = 20)
plt.plot(history.history['loss'], label = 'train')
plt.plot(history.history['val_loss'], label = 'validation')
plt.legend(fontsize = 18)
plt.ylabel('MAE', fontsize = 18)
plt.xlabel('Epoch', fontsize = 18)
plot_name = model_name.split('.')[0]+'.pdf' # changes the format of file to pdf for saving the plot
plt.savefig(plot_name)

# Load best model
model.load_weights(model_name)

# Making prediction
from sklearn.metrics import confusion_matrix, plot_confusion_matrix
y_pred2=model.predict_classes(X_test)
y_true=np.argmax(y_test, axis=1)

# Evaluation on test dataset
test_loss, test_acc = model.evaluate(X_test, y_test, batch_size=32)
print("Loss on test set: ", test_loss)
print("Accuracy on test set: ", test_acc)
cm  = confusion_matrix(y_true, y_pred2)
print(cm)

# Calculate TN, FP, FN, TP for sensitivity, etc.
true_negative, false_positive, false_negative, true_positive  = cm.ravel()
precision = true_positive / (true_positive + false_positive)
recall = true_positive / (true_positive + false_negative)
specificity = true_negative / (true_negative + false_positive)

print('Precison:{:.2f}'.format(precision))
print('Sensitivity:{:.2f}'.format(recall))
print('Specificity:{:.2f}'.format(specificity))

# AUC
from sklearn.metrics import roc_auc_score
auc = roc_auc_score(y_true, y_pred2)
print(f'AUC: {auc}')